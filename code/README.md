# Code

Use this folder for the code related to your project.

MATHiR Threes: https://spraakbanken.gu.se/en/resources/mathir-trad
MATHiR Words: https://spraakbanken.gu.se/en/resources/mathir-ord

## TODO

1. script for extracting all tokens (`form='aff'`) from the MATHir Trees files and saving them in a file, one token per line, called tokens.txt:

\[...\] <br>
af <br>
iordh <br>
oc <br>
hans <br>
qwinna <br>
\[...\] <br>

2. script for extracting all lemmas (`lemma='af'`) from the MATHiR Tree files 

## FINDOUT

1. Is a target lexicon needed for lookup normalization? - No!
2. Is a target lexicon needed for weighted Levenshtein distance (WLD) normalization? 
3. Is the parameter file for WLD automatically generated?
